{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Leistungsmessung\n",
    "\n",
    "Während der Erarbeitung und Analyse zu Spark und Gensim wurden auch verschiedene Testläuft durchgeführt. Dabei wurden die Zeiten gemessen, welche Spark oder Gensim benötigt haben, um die verwendeten Daten zu verarbeiten. Dabei ist zu beachten, dass die Vorverarbeitung der Daten jeweils in Spark geschieht und die Unterschiede durch die Verarbeitung der Daten (also der Modellerstellung) mit Spark, bzw. Gensim, zustandekommen. Die Zeiten unserer Testdurchläufe haben wir in den folgenden Diagrammen grafisch aufbereitet. Für die Tests wurden Datensätze mit 10, 100, 150, 1.000 und 10.000 MegaByte (MB)verwendet. Der Fokus hierbei lag auf den Datensätzen bis 1.000 MB.\n",
    "<br>Alle Tests wurden auf derselben Hardware durchgeführt, einem „HP Spectre x360 15-df0126ng“.\n",
    "\n",
    "   - CPU    = Intel Core i7-8750H mit 6 x 2,2GHz (TurboBoost: 4,1GHz)\n",
    "   - RAM    = 2 x 8GB DDR4\n",
    "\n",
    "Bei den Messungen wurden Messungen für Gensim im SingleCore Modus (SC) und im MultiCore Modus (MC) durchgeführt, da hier der Modus selbst gewählt werden kann.<br>\n",
    "Die ersten Tests wurden mit dem Local-Mode von Spark durchgeführt. Dabei ist aufgefallen, dass hier der Rechner mit 16 GB Arbeitsspeicher immer wieder an seine Grenzen gekommen ist. Spark hatte bereits ab einem Datensatz von 150 MB Probleme („out of memory – error“). Unter Gensim trat dieses Problem erst bei dem Datensatz mit 1.000 MB auf.\n",
    "\n",
    "<img src=\"Diagramm_01.png\">\n",
    "\n",
    "Vergleicht man die Zeiten fällt direkt auf, dass Spark im Local Mode deutlich schneller bei der Berechnung ist als Gensim. Dabei sind vor allem die Werte des MC-Modus mit Spark zu vergleichen, da Spark ebenfalls im Mehrkernbetrieb operiert.<br>\n",
    "Im Anschluss daran haben wir den Standalone Mode von Spark verwendet. Die Testläufe wurden jeweils mit 2 Workern durchgeführt und die Anzahl der CPU-Kerne von Test zu Test verändert. Jedem Worker standen 8 GB Arbeitsspeicher zur Verfügung.<br>\n",
    "Hier konnten die Spark Tests erfreulicherweise mit allen Datensätzen durchgeführt werden. Zum Schluss haben wir noch einen 10.000 MB Datensatz getestet und konnten eine Durchlaufzeit von 1:07:51, bei 2 Workern mit je 4 CPU-Kernen und jeweils 8 GB Arbeitsspeicher, erzielen. \n",
    "\n",
    "<img src=\"Diagramm_02.png\">\n",
    "\n",
    "Die erste Darstellung zeigt die Entwicklung der Durchlaufzeiten für die jeweiligen Datensätze. Angefangen mit 10 MB hin zu 1.000 MB. Dabei ist ersichtlich, dass die Zeiten bei kleinen Datensätzen relativ ähnlich sind, sobald wir aber 1.000 MB verwenden, die Zeiten auseinanderdriften.\n",
    "\n",
    "<img src=\"Diagramm_03.png\">\n",
    "\n",
    "Das zweite Diagramm stellt die Zeiten im Vergleich zu den verwendeten CPU-Kernen dar. Dabei fällt auf, dass die beste Kombination in diesem Testfall der Datensatz mit 1.000 MB und je 4 CPU Kernen pro Worker zu sein scheint. Bei den kleineren Datenmengen waren die Zeiten, trotz verschiedener Konfigurationen, sehr konstant.<br>\n",
    "Im Anschluss daran haben wir uns gefragt, wie sich die Dauer wohl mit einem extrem großen Datensatz entwickeln würde und einen Datensatz mit 10.000 MB verwendet. Die Daten dazu sind im nachfolgenden Diagramm zu finden.\n",
    "\n",
    "<img src=\"Diagramm_04.png\">\n",
    "\n",
    "Vergleicht man den Anstieg der Zeiten kann man feststellen, dass die Dauer im Verhältnis zur Datenmenge weniger zunimmt. Bei der grauen Linie, welche der leistungsstärksten Konfiguration entspricht, hätten bei linearem Verlauf durch die anfangs 18 Sekunden für 10 MB die folgenden Werten für die anderen Datensätze erwartet werden können:<br>\n",
    "- 100 MB    = 180 statt 64 Sekunden       -> 35% der Zeit\n",
    "- 1.000 MB  = 1.800 statt 512 Sekunden    -> 28% der Zeit\n",
    "- 10.000 MB = 18.000 statt 4.071 Sekunden -> 22% der Zeit<br>\n",
    "Dadurch wird ersichtlich, dass die Datenverarbeitung mit Spark tatsächlich auf sehr große Datensätze ausgelegt ist und dort ihre Vorteile erst richtig entfalten kann. Je größer die Datensätze in unserem Beispiel wurden, desto mehr Zeit konnte im Verhältnis eingespart werden.\n",
    "\n",
    "Um zu überprüfen, ob sich der Trend mit geringeren Durchlaufzeit bei der Konfiguration mit je 4 CPU-Kernen fortsetzt, wurde zusätzlich noch eine Messung mit dieser Konfiguration und dem 10.000 MB Datensatz durchgeführt. Auch hier war die Durchlaufzeit geringer als mit 6 CPU-Kernen je Worker. Jedoch ist der Abstand hier im Verhältnis zueinander nichtmehr so groß wie zuvor. \n",
    "<br>\n",
    "Für unsere Tests mit Gensim haben wir eine Art Abkürzung gewählt und nur 2 verschiedene Konfigurationen für den Standalone Mode verwendet. Einmal mit 2 CPU-Kernen je Worker und einmal 6 CPU-Kerne je Worker, da hier vor allem die Unterschiede zwischen Single- und Multi-Core Verarbeitung durch Gensim im Vordergrund standen. Messungen mit 1.000 MB großen Datensätzen konnten aufgrund des dann auftretenden „out of memory“ Fehlers – also aufgrund von Arbeitsspeichermangel - nicht durchgeführt werden.\n",
    "\n",
    "<img src=\"Diagramm_05.png\">\n",
    "\n",
    "Deutlich zu sehen in der obigen Grafik ist, dass es quasi keine Auswirkung hat wie viele CPU-Kerne dem Standalone Modus von Spark zur Verfügung stehen. Dafür hängt es umso mehr davon ab, ob Gensim im Singlecore oder im Multicore Modus ausgeführt wird. Der Multicore Modus reduziert die jeweilige Bearbeitungszeit deutlich. Auch zu beobachten ist, dass der Datensatz mit den 150 MB im Multicore Modus schneller bearbeitet werde konnte als der Datensatz mit 100 MB (siehe Diagramm unten). Dies lässt darauf schließen, dass hier ebenfalls eine Steigerung der Geschwindigkeit im Verhältnis zur Datenmenge feststellbar ist, wenn die Datensätze größer werden.<br>\n",
    "Dies ist in der nachfolgenden Grafik nochmals deutlich eindeutiger zu sehen:\n",
    "\n",
    "<img src=\"Diagramm_06.png\">\n",
    "\n",
    "Bei sehr kleinen Datensätzen kann in der Ausführungsdauer kaum ein Unterschied beobachtet werden. Bei großen Datensätzen ist also vor allem die Durchführung mit mehreren CPUs von entscheidender Bedeutung.<br>\n",
    "\n",
    "Durch unsere Messungen konnten wir schlussendlich mehrere Kernpunkte identifizieren:\n",
    "-\tJe größer die Datenmenge ist, desto besser performen sowohl Spark als auch Gensim.\n",
    "-\tBei lokaler Durchführung stoßen normale Computer schnell an ihre Leistungsgrenzen, vor allem den Arbeitsspeicher betreffend, wenn große Datenmengen verwendet werden.\n",
    "-\tSpark ist deutlich performanter als Gensim und führ die Verarbeitung der Daten deutlich schneller durch.\n",
    "-\tAuch bei großen Datenmengen kann es einen Unterschied machen wie viele Hardware-Ressourcen verwendet werden, da eine höhere Parallelisierung auch immer mehr Koordination und Kommunikation benötigt.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
